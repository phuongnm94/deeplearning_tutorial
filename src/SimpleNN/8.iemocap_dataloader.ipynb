{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type roberta to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np \n",
    " \n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "\n",
    "from transformers import BertConfig, AutoTokenizer, AutoModel\n",
    "import json\n",
    "import random\n",
    "# =====================\n",
    "\n",
    "def set_random_seed(seed: int):\n",
    "    \"\"\"set seeds for reproducibility\"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    \n",
    "set_random_seed(7)\n",
    "\n",
    "train_data = json.load(open('data/iemocap.train.flatten.json'))\n",
    "all_labels = []\n",
    "for sample in train_data:\n",
    "    all_labels.append(sample[1])\n",
    "\n",
    "\n",
    "# count label \n",
    "num_labels = len(set(all_labels))\n",
    " \n",
    "\n",
    "# init model \n",
    "# Load config from pretrained name or path \n",
    "pre_trained_model_name = 'roberta-base'\n",
    "config = BertConfig.from_pretrained(pre_trained_model_name)  # Load pretrained bert\n",
    "bert_tokenizer = AutoTokenizer.from_pretrained(pre_trained_model_name)\n",
    "\n",
    "class BatchPreprocessor(object): \n",
    "\n",
    "    def __call__(self, batch):\n",
    "        raw_sentences = []\n",
    "\n",
    "        # collect all sentences\n",
    "        for sample in batch:\n",
    "            raw_sentences.append(sample[0])\n",
    "\n",
    "        # label processing \n",
    "        labels = []\n",
    "        for sample in batch:\n",
    "            label = sample[1]\n",
    "            labels.append(int(label))\n",
    "\n",
    "        word_ids_from_bert_tokenizer = bert_tokenizer(raw_sentences,  padding='max_length', max_length=512, truncation=True, return_tensors='pt')\n",
    "\n",
    "        return (word_ids_from_bert_tokenizer, torch.FloatTensor(labels), raw_sentences) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First epoch data:\n",
      "input data\n",
      " {'input_ids': tensor([[    0,  1185,   214,  ...,     1,     1,     1],\n",
      "        [    0,  3084,  7252,  ...,     1,     1,     1],\n",
      "        [    0,  9904,     9,  ...,     1,     1,     1],\n",
      "        ...,\n",
      "        [    0, 33082,     4,  ...,     1,     1,     1],\n",
      "        [    0,  3684,   235,  ...,     1,     1,     1],\n",
      "        [    0, 10127,  5219,  ...,     1,     1,     1]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]])}\n",
      "label data\n",
      " tensor([3., 5., 1., 2., 1., 1., 2., 5., 2., 5., 3., 2., 3., 5., 4., 4., 2., 1.,\n",
      "        5., 2., 4., 2., 4., 5., 2., 5., 5., 1., 1., 2., 3., 3.])\n",
      "padding mask data\n",
      " [\"You're an autono- autonomous human being.  You could- You could go into the com-\", \"No um, I don't want to argue with him, but it's time we realized that nobody else believes that Larry is alive.\", 'Yes of course, of course.', \"But you've got to keep looking for other stuff. You've got to do it on your own, too.  Okay?\", \"I'll tell them I'm sick and that you can't leave something.\", 'Yeah.  And they were really supportive, like through the whole process, but-', 'What flashlight?', \"Right, well, when you're at home and you lose something, do you guarantee that you're going to find it later on?\", \"Yeah I mean, Your bag might have been confiscated because it's --\", \"Uh, God.  I don't know what to do anymore.  Like I said --\", \"I still can't live on in six seven and five.  It's not possible in Los Angeles.  Housing is too expensive.\", 'Okay, And uh- go ahead and click on run.', \"This is ridiculous.  I- I seriously, I don't understand why you think these automated systems are supposed to like work for anybody.  They have never, ever work for me.\", 'I mean, some information here would be great.  Some help.  Can you, like, type something in and find out?', 'Woo-', \"Oh, I didn't hit you very hard.\", 'I kwon, it is ridiculous', 'Oh gee.', \"I don't know what to tell you, babe. Maybe- Maybe you're right.  Maybe you do have to go someplace else.  I don't know, maybe it's just not meant to be here.  I mean I want you to-I don't want you to give up, but I mean I don't want you to move away, but at the same time, I don't like seeing you like this.\", 'Yeah, well the chances of it being lost forever, you know, are slight because -- -- you were in the --', 'The worst one was in Cannes when your curling irons burnt a hole in my new dressing gown.', 'Not- Not selling pot, right?', \"Are you cold?  Do you want my jacket?  We should have brought the blanket, our blanket.  Oh, this is great.  I didn't even think to bring a six pack.  Oh, a six pack would be just the ticket right about now.\", 'A poodle, a backrub, a spa, a suicide pack?  What, Carla, what the hell do you want?', 'How did you know?', \"Well, then you're just gonna look stupid because I'm just waiting for an I.D. and you're gonna make security take me out because I want my I.D.\", \"Obviously ma'am.\", \"All- I'll write you everyday, all the time.  And I'll send you pictures and you send me pictures. I know We've got email out there.  We've got email and I can see stuff and you can send me stuff all the time.  Okay?\", \"It's- It's mixed up with so many other things, I-\", 'Okay.', \"All right!  But don't think like that, because I mean, what the hell did we do all this for, Chris?  The whole business it's all for you!  The whole shooting match is for you!\", 'Amanda-- Listen- Listen-']\n",
      "cpu\n"
     ]
    }
   ],
   "source": [
    "\n",
    "batch_size = 32\n",
    "data_folder= \"data/\"\n",
    "\n",
    "# dataset_example should support operator index_selection for create the data_loader object\n",
    "test_loader = DataLoader(json.load(open(f\"{data_folder}/iemocap.test.flatten.json\")), batch_size=batch_size, collate_fn=BatchPreprocessor(), shuffle=True)\n",
    "train_loader = DataLoader(json.load(open(f\"{data_folder}/iemocap.train.flatten.json\")), batch_size=batch_size, collate_fn=BatchPreprocessor(), shuffle=True)\n",
    "valid_loader = DataLoader(json.load(open(f\"{data_folder}/iemocap.valid.flatten.json\")), batch_size=batch_size, collate_fn=BatchPreprocessor(), shuffle=True)\n",
    "for e in test_loader:\n",
    "    print('First epoch data:')\n",
    "    print('input data\\n', e[0])\n",
    "    print('label data\\n',e[1])\n",
    "    print('padding mask data\\n',e[2])\n",
    "    print(e[0]['input_ids'].device)\n",
    "    break  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size 162\n",
      "test size 51\n"
     ]
    }
   ],
   "source": [
    "print('train size', len(train_loader))\n",
    "print('test size',  len(test_loader))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.16 (conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d3602b4515afb2d87a870b61c65d7b658117eca8f37f64d20593019ba04f7019"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise\n",
    "![emo](../../img/emotion_attn.jpg)\n",
    "\n",
    "The follow architecture learn the attention between 2 sequences\n",
    "- sequence 1 = list of utterance vector in a conversation \n",
    "- sequence 2 = list of emotional states \n",
    "\n",
    "The emotion modeling learn attention score between each emotional embedding vector to one utterance in a conversation. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 28, 1024])\n",
      "tensor([[[ 0.9697,  0.9039, -0.0701,  ...,  0.5094,  0.2374,  0.0256],\n",
      "         [ 0.6522,  0.6262,  0.6917,  ...,  0.7178, -0.0460, -0.0189],\n",
      "         [ 0.8739,  0.4841, -0.1978,  ...,  0.3813,  0.1911,  0.4049],\n",
      "         ...,\n",
      "         [ 0.9867,  0.8559,  0.2563,  ...,  0.2989,  0.3214,  0.1211],\n",
      "         [ 0.9257,  0.8594,  0.3799,  ...,  0.6919,  0.6951,  0.0596],\n",
      "         [ 0.6474,  0.2404,  0.5562,  ...,  0.4149,  0.6807,  0.1836]],\n",
      "\n",
      "        [[ 1.0677,  0.8821,  0.2880,  ...,  0.6911,  0.5485,  0.2077],\n",
      "         [ 0.2921,  0.2314,  0.0511,  ...,  0.6091,  0.5586,  0.4750],\n",
      "         [ 0.7953,  0.9865,  0.4475,  ...,  0.0510,  0.1657,  0.3726],\n",
      "         ...,\n",
      "         [ 0.6023,  0.1709,  0.4099,  ...,  0.6038,  0.3145,  0.6336],\n",
      "         [ 0.7767,  1.0490, -0.0244,  ...,  0.2845,  0.1319,  0.6853],\n",
      "         [ 0.2902,  0.8018,  0.3284,  ...,  0.6934, -0.2423,  0.5644]]],\n",
      "       grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "from torch import nn \n",
    "import math\n",
    "\n",
    "# Setting for model architecture  \n",
    "d_model = 1024\n",
    "embedding_size = d_model\n",
    "batch_size = 2\n",
    "num_labels = 6\n",
    "sequence_length = 28\n",
    "num_layer = 1\n",
    "nhead = 4 # this is a special setting (number of head) for Transformer architecture \n",
    "\n",
    "# ================\n",
    "# fake input data \n",
    "fake_utterance_fused_by_context = torch.rand(batch_size, sequence_length, embedding_size)\n",
    "fake_mask=torch.LongTensor(batch_size, sequence_length).fill_(0)\n",
    "fake_mask[:, -2] = 1\n",
    "fake_mask[:, -1] = 1\n",
    "fake_mask = (fake_mask == 1)\n",
    "# ================\n",
    "\n",
    "# model init \n",
    "attention_modeling = nn.MultiheadAttention(d_model, num_heads=8, dropout=0.2, batch_first=True)\n",
    "emotion_emb = nn.Embedding(num_labels, d_model)\n",
    "\n",
    "# forward model  \n",
    "v_fused_context_and_emotion, attentions = attention_modeling(fake_utterance_fused_by_context,  # query vector\n",
    "                                                                emotion_emb.weight.unsqueeze(0).repeat(batch_size, 1, 1), # key vector\n",
    "                                                                emotion_emb.weight.unsqueeze(0).repeat(batch_size, 1, 1), # value vector\n",
    "                                                                )\n",
    "v_fused_context_and_emotion = fake_utterance_fused_by_context + v_fused_context_and_emotion\n",
    "\n",
    "# output shape  \n",
    "print(v_fused_context_and_emotion.shape)\n",
    "print(v_fused_context_and_emotion)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([6, 1024]), torch.Size([2, 28, 1024]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotion_emb.weight.shape, fake_utterance_fused_by_context.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.16 (conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d3602b4515afb2d87a870b61c65d7b658117eca8f37f64d20593019ba04f7019"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

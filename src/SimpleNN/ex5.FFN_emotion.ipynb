{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**\n",
    "\n",
    "Desing a FFN Neural network that learn to classify the emotional label of a given input sentence. We assum that, each word in the input sentence have a weight affect to the label. To this end, we need to learn these hidden weights.\n",
    "\n",
    "**tips**: *design a Embedding layer (random init) to convert word to vector. Then `sum` all word embedding vectors, then transform document vector to the label values (images)*\n",
    "\n",
    "![model_arc](../../img/dl_tutorial-Trang-2.drawio.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No config specified, defaulting to: emotion/split\n",
      "Found cached dataset emotion (/home/phuongnm/.cache/huggingface/datasets/emotion/split/1.0.0/cca5efe2dfeb58c1d098e0f9eeb200e9927d889b5a03c67097275dfb5fe463bd)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "674725cce5b347568017c896a337d0bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np \n",
    " \n",
    "# =====================\n",
    "\n",
    "from torchtext.vocab import vocab\n",
    "from collections import Counter, OrderedDict\n",
    "from datasets import load_dataset\n",
    "import re\n",
    "\n",
    "def split_tokens(sentence):                             \n",
    "    return [w for w in re.split(r\" +\",  re.sub(r\"[^a-z@# ]\", \"\", sentence.lower()))]   \n",
    "\n",
    "dataset = load_dataset('emotion')\n",
    "train_data = dataset['train']\n",
    "all_words = []\n",
    "all_labels = []\n",
    "for sample in train_data:\n",
    "    all_words+= split_tokens(sample['text']) \n",
    "    all_labels.append(sample['label'])\n",
    "\n",
    "# build vocab - using vocab object of torchtext \n",
    "counter = Counter(all_words)\n",
    "sorted_by_freq_tuples = sorted(counter.items(), key=lambda x: x[1], reverse=True)\n",
    "my_vocab = vocab(OrderedDict(sorted_by_freq_tuples), specials=['<pad>','<unk>'])\n",
    "my_vocab.set_default_index(my_vocab['<unk>'])\n",
    "\n",
    "# count label \n",
    "num_labels = len(set(all_labels))\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "\n",
    "def convert_sentence_to_ids(sentence, vocab):    \n",
    "    word_ids = None\n",
    "    # - split sentence to tokens using `split_tokens` defined above\n",
    "    # (tips: split sentence to list of words, then feed to the vocab to get list of id) \n",
    "    word_ids = vocab(split_tokens(sentence))\n",
    "\n",
    "    # ===================================\n",
    "    return word_ids\n",
    "\n",
    "\n",
    "def get_max_sentence_length_in_batch(batch_input_ids): \n",
    "    # - find and return the MAXIMUM length (number of word) of each sample (sentence) in a batch.\n",
    "    \n",
    "    max_sentence_length = max([len(e) for e in batch_input_ids])\n",
    "    return max_sentence_length\n",
    "\n",
    "\n",
    "def add_padding(batch_input_ids, padding_id):\n",
    "    max_sample_len_in_batch = get_max_sentence_length_in_batch(batch_input_ids=batch_input_ids)\n",
    "\n",
    "    # - batch data contains many sentence having difference number of words. To train a deep learning model\n",
    "    #   we need to convert it to tensor which have the same length for all sentences. \n",
    "    # - We need to add padding into each sentence (sample) in a batch. \n",
    "    # - for example: a batch contains [[1,2,3,4],[6,7,8],[9]] ==(after padding 0)==> [[1,2,3,4],[6,7,8,0],[9,0,0,0]]\n",
    "    # (tips: each sample, calculate the number of padding tokens need to add to get max_sample_len_in_batch) \n",
    "    padded_word_ids = []\n",
    "    for i, word_ids in enumerate(batch_input_ids):\n",
    "        padded_word_ids.append(word_ids + [padding_id] * (max_sample_len_in_batch - len(word_ids)))\n",
    "    return padded_word_ids\n",
    "\n",
    "\n",
    "class BatchPreprocessor(object):\n",
    "    def __init__(self, vocab):\n",
    "        self.vocab = vocab \n",
    "\n",
    "    def __call__(self, batch):\n",
    "        inputs = []\n",
    "        masks = []\n",
    "\n",
    "        # covert text to number \n",
    "        for sample in batch:\n",
    "            word_ids = convert_sentence_to_ids(sample['text'], self.vocab)\n",
    "            inputs.append(word_ids)\n",
    "        \n",
    "        # padding to create a tensor input - make all sentence having the same length \n",
    "        padding_id = self.vocab[\"<pad>\"]\n",
    "        padded_batch = add_padding(batch_input_ids=inputs, padding_id=padding_id)\n",
    "\n",
    "        # label processing \n",
    "        labels = []\n",
    "        for sample in batch:\n",
    "            label = sample['label']\n",
    "            labels.append(int(label))\n",
    "\n",
    "        # make a tensor \n",
    "        inputs = torch.LongTensor(padded_batch)\n",
    "\n",
    "        # make mask flag tensor\n",
    "        masks = inputs == padding_id\n",
    "\n",
    "        return (inputs, torch.FloatTensor(labels), torch.BoolTensor(masks)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First epoch data:\n",
      "input data\n",
      " tensor([[   2,   70,   17,  ...,    0,    0,    0],\n",
      "        [   2,    3,   14,  ...,    0,    0,    0],\n",
      "        [   2,   24,    8,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [   2,    3,  723,  ...,    0,    0,    0],\n",
      "        [   2, 1293,    6,  ...,    0,    0,    0],\n",
      "        [   2,    3,  110,  ...,    0,    0,    0]])\n",
      "label data\n",
      " tensor([0., 1., 1., 3., 2., 0., 1., 0., 0., 1., 1., 1., 1., 3., 3., 4., 0., 4.,\n",
      "        1., 0., 4., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 0., 3., 0., 2.,\n",
      "        1., 4., 1., 0., 1., 4., 1., 0., 0., 1., 1., 2., 2., 4., 0., 0., 4., 2.,\n",
      "        3., 4., 0., 1., 2., 2.])\n",
      "padding mask data\n",
      " tensor([[False, False, False,  ...,  True,  True,  True],\n",
      "        [False, False, False,  ...,  True,  True,  True],\n",
      "        [False, False, False,  ...,  True,  True,  True],\n",
      "        ...,\n",
      "        [False, False, False,  ...,  True,  True,  True],\n",
      "        [False, False, False,  ...,  True,  True,  True],\n",
      "        [False, False, False,  ...,  True,  True,  True]])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "batch_size = 60\n",
    "\n",
    "# dataset_example should support operator index_selection for create the data_loader object\n",
    "test_loader = DataLoader(dataset['test'], batch_size=batch_size, collate_fn=BatchPreprocessor(my_vocab), shuffle=True)\n",
    "train_loader = DataLoader(dataset['train'], batch_size=batch_size, collate_fn=BatchPreprocessor(my_vocab), shuffle=True)\n",
    "valid_loader = DataLoader(dataset['validation'], batch_size=batch_size, collate_fn=BatchPreprocessor(my_vocab), shuffle=True)\n",
    "for e in test_loader:\n",
    "    print('First epoch data:')\n",
    "    print('input data\\n', e[0])\n",
    "    print('label data\\n',e[1])\n",
    "    print('padding mask data\\n',e[2])\n",
    "    break  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size 267\n",
      "test size 34\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "15214"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('train size', len(train_loader))\n",
    "print('test size',  len(test_loader))\n",
    "len(my_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "\n",
    "\n",
    "d_model = 200\n",
    "word_embedding = nn.Embedding(num_embeddings=len(my_vocab), embedding_dim=d_model, padding_idx=my_vocab['<pad>'])\n",
    "word_embedding.cuda()\n",
    "\n",
    "# ===================================\n",
    "# REQUIREMENT:\n",
    "# - construct a Linear (dense connection) layer to transform a document vector (embedding size) to 1 \n",
    "# - NOTE: then move this layer to CUDA device for computation \n",
    "# ===================================\n",
    "# - PUSH YOUR CODE IN HERE, can not modify any code in outside this range.  \n",
    "\n",
    "output_layer = None\n",
    "# ===================================\n",
    "\n",
    "# loss also is supported by a library \n",
    "loss_computation = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(list(word_embedding.parameters()) + list(output_layer.parameters()), lr = 1e-3)    # using Adam optimizer instead of SGD\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_function(w_vectors, output_module):\n",
    "    # ===================================\n",
    "    # REQUIREMENT: compute emotion prediction values given all word embedding vectors \n",
    "    # we assum that, each word in the input sentence have a weight effect to the label\n",
    "    # and we need to learn these hidden weights.\n",
    "    #\n",
    "    # - Compute the document vector based on the input word embedding vector based on sum operator. \n",
    "    #   e.g. doc1 = sum([w1, w2, ... wn]) = w1 + w2 + ... + wn \n",
    "    #   NOTE: check function `torch.sum` (https://pytorch.org/docs/stable/generated/torch.sum.html)\n",
    "    #\n",
    "    # - forward the document vector to `output_module` layer to get emotion values. \n",
    "    # ===================================\n",
    "    # - PUSH YOUR CODE IN HERE, can not modify any code in outside this range. \n",
    " \n",
    "    label_vectors = None\n",
    "    # ===================================\n",
    "    return label_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc model BEFORE train =  tensor(0.1310, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "def eval(data_loader):\n",
    "    count_true = 0\n",
    "    count_total = 0\n",
    "    for batch in data_loader:\n",
    "\n",
    "        x, y_gold, masked = batch\n",
    "\n",
    "        x = x.cuda()\n",
    "        y_gold = y_gold.cuda()\n",
    "        \n",
    "        # ============= ###### IMPORTANT ######## ===============\n",
    "        # Forward pass: Compute predicted y by passing x to the model\n",
    "        w_vectors = word_embedding(x) #  batch size x sequence length x hidden size \n",
    "        label_vectors = forward_function(w_vectors=w_vectors, output_module=output_layer)\n",
    "        \n",
    "        predictions = torch.ceil(label_vectors.squeeze())\n",
    "        # ============= ######################### ===============\n",
    "\n",
    "        count_true += torch.sum((predictions==y_gold) == True)\n",
    "        count_total += x.shape[0]\n",
    "\n",
    "    return count_true / count_total\n",
    "print('Acc model BEFORE train = ', eval(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch/batch:  0  avg loss:  3.7099706077397094 Acc= tensor(0.1860, device='cuda:0')\n",
      "epoch/batch:  1  avg loss:  1.8406190037280878 Acc= tensor(0.2255, device='cuda:0')\n",
      "epoch/batch:  2  avg loss:  1.2563680033112286 Acc= tensor(0.2955, device='cuda:0')\n",
      "epoch/batch:  3  avg loss:  0.8811012373658155 Acc= tensor(0.3145, device='cuda:0')\n",
      "epoch/batch:  4  avg loss:  0.6801902278978726 Acc= tensor(0.3490, device='cuda:0')\n",
      "epoch/batch:  5  avg loss:  0.5625927380185002 Acc= tensor(0.3410, device='cuda:0')\n",
      "epoch/batch:  6  avg loss:  0.48991260730595176 Acc= tensor(0.3585, device='cuda:0')\n",
      "epoch/batch:  7  avg loss:  0.4360239225045572 Acc= tensor(0.3315, device='cuda:0')\n",
      "epoch/batch:  8  avg loss:  0.39910079287679007 Acc= tensor(0.3885, device='cuda:0')\n",
      "epoch/batch:  9  avg loss:  0.37134649389692015 Acc= tensor(0.3775, device='cuda:0')\n",
      "epoch/batch:  10  avg loss:  0.35205166415775313 Acc= tensor(0.3755, device='cuda:0')\n",
      "epoch/batch:  11  avg loss:  0.3304659425933263 Acc= tensor(0.3355, device='cuda:0')\n",
      "epoch/batch:  12  avg loss:  0.3192284724462345 Acc= tensor(0.3000, device='cuda:0')\n",
      "epoch/batch:  13  avg loss:  0.3062295797054241 Acc= tensor(0.3115, device='cuda:0')\n",
      "epoch/batch:  14  avg loss:  0.2934410443968987 Acc= tensor(0.3485, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "MAX_EPOCHS=15\n",
    "for epoch in range(MAX_EPOCHS):\n",
    "    avg_loss = 0.0\n",
    "    for batch in train_loader:\n",
    "\n",
    "        x, y_gold, masked = batch\n",
    "\n",
    "        x = x.cuda()\n",
    "        y_gold = y_gold.cuda() \n",
    "        \n",
    "\n",
    "        # ============= ###### IMPORTANT ######## ===============\n",
    "        # Forward pass: Compute predicted y by passing x to the model\n",
    "        w_vectors = word_embedding(x) #  batch size x sequence length x hidden size  \n",
    "\n",
    "        label_vectors = forward_function(w_vectors=w_vectors, output_module=output_layer)\n",
    "\n",
    "        # Compute and loss = average ((out_put - pred) ^ 2)\n",
    "        loss = loss_computation(label_vectors.squeeze(), y_gold) \n",
    "        # ============= ######################### ===============\n",
    "\n",
    "        # perform a backward pass (backpropagation) => to compute the gradient values in Tensor weights\n",
    "        loss.backward()\n",
    "        avg_loss += loss.item()\n",
    "\n",
    "        # USE LIBRARY: 'model.parameters()' in stead of 'model.get_parameter()' is implemented by library, also return list of parameters: \"weight\" and \"bias\" \n",
    "        # Optimizer step(), this update gradient values to weights.\n",
    "        optimizer.step() # instead of `param.add_(-lr * param.grad)` => update weight values\n",
    "        optimizer.zero_grad() # instead of `param.grad.fill_(0)` => remove all the old gradient values in all Tensor weight\n",
    "    \n",
    "    avg_loss = avg_loss / len(train_loader)\n",
    "    if avg_loss < 0.0001:\n",
    "        print(loss)\n",
    "        break\n",
    "    print('epoch/batch: ', epoch, ' avg loss: ', avg_loss, \"Acc=\", eval(valid_loader))\n",
    "    # break \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc model AFTER train =  tensor(0.3335, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print('Acc model AFTER train = ', eval(test_loader))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.16 (conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d3602b4515afb2d87a870b61c65d7b658117eca8f37f64d20593019ba04f7019"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
